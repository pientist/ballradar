# Set Transformer in `pytorch`
This an implementation of [Set Transformer: A Framework for Attention-based Permutation-Invariant Neural Networks](https://arxiv.org/abs/1810.00825).

## How to use this code
Just run `python train.py`.

## Requirements
1. pytorch 1.3
2. numpy 1.17, matplotlib 3.1, tqdm 4.32
3. (optional) [NVIDIA/apex](https://github.com/NVIDIA/apex/tree/088985936518be7e25795a30d8ab33affa9db6ed)

## Credit
This code is partially based on [jadore801120/attention-is-all-you-need-pytorch](https://github.com/jadore801120/attention-is-all-you-need-pytorch).
